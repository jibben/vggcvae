{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial, reduce\n",
    "import os.path\n",
    "import os\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.ndimage import imread\n",
    "\n",
    "from keras.layers import Flatten, Reshape, Input, Dense, Lambda, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, ZeroPadding2D, UpSampling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, Callback\n",
    "from keras.metrics import binary_crossentropy\n",
    "from keras.engine.topology import Layer\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import keras.optimizers\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "K.set_floatx('float32')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna play around with mnist data to start, just for proof of concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom layer to calculate our CVAE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# because Keras isn't powerful to handle the loss for a CVAE\n",
    "# we have to create an actual loss layer to calculate it\n",
    "\n",
    "class CVAELossLayer(Layer):\n",
    "    def __init__(self, latent_dim, image_size, **kwargs):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        self.is_placeholder = True\n",
    "        \n",
    "        super(CVAELossLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def calculate_loss(self, inputs):\n",
    "        x = inputs[0]\n",
    "        z_mean = inputs[1][:,:self.latent_dim]\n",
    "        z_log_sigma = inputs[1][:,self.latent_dim:]\n",
    "        dec_x = inputs[2]\n",
    "        \n",
    "        # we add 1e-10 to avoid any possible overflow due to the log calculated within binary_crossentropy\n",
    "        output_loss = self.image_size * K.mean(K.binary_crossentropy(dec_x + 1e-10, x + 1e-10), axis=-1)\n",
    "        \n",
    "        # this is the Kullback Libeler divergence between the\n",
    "        # distribution in latent space and the prior\n",
    "        latent_loss = - 0.5 * K.sum(1 + K.clip(z_log_sigma, 1e-10, 1e10) - K.clip(K.square(z_mean), 1e-10, 1e10) - K.clip(K.exp(z_log_sigma), 1e-10, 1e10), axis = -1)\n",
    "        \n",
    "        return K.mean(output_loss + latent_loss)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        loss = self.calculate_loss(inputs)\n",
    "        # this is the hacky way to calculate our loss\n",
    "        # we use the inputs given to calculate the loss\n",
    "        # and then return it for direct use for fitting\n",
    "        return loss\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to ensure we have the right amount of padding\n",
    "def build_padding(v_rem, h_rem, mult):\n",
    "    lay = None\n",
    "    \n",
    "    v_pad = 0\n",
    "    h_pad = 0\n",
    "    \n",
    "    if v_rem >= mult:\n",
    "        v_rem -= mult\n",
    "        v_pad = 1\n",
    "\n",
    "    if h_rem >= mult:\n",
    "        h_rem -= mult\n",
    "        h_pad = 1\n",
    "    \n",
    "    if h_pad or v_pad:\n",
    "        lay = ZeroPadding2D(padding=(v_pad, h_pad))\n",
    "        \n",
    "    return lay, v_rem, h_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_sample(latent_dims, inputs):\n",
    "    z_mean = inputs[:,:latent_dims]\n",
    "    z_log_sigma = inputs[:,latent_dims:]\n",
    "\n",
    "    eps = K.random_normal(shape=(latent_dims,), mean=0.0, stddev=1.0, dtype='float32')\n",
    "    \n",
    "    return z_mean + (K.exp(z_log_sigma) * eps)\n",
    "\n",
    "\n",
    "def sample_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 2\n",
    "    shape[1] //= 2\n",
    "    return tuple(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally the code to build the net itself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a helper function to demo a model on a given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def demo_model(model, data, shape, show_latent=False):\n",
    "    e = model.layers[1]\n",
    "    d = model.layers[2]\n",
    "    \n",
    "    batch_size = data.shape[0]\n",
    "    \n",
    "    vecs = e.predict(data, batch_size = batch_size, verbose=0)\n",
    "    pred = d.predict(vecs, batch_size = batch_size, verbose=0)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        fig = plt.figure()\n",
    "        a=fig.add_subplot(1,2,1)\n",
    "        a.spines['top'].set_color('none')\n",
    "        a.spines['bottom'].set_color('none')\n",
    "        a.spines['left'].set_color('none')\n",
    "        a.spines['right'].set_color('none')\n",
    "        a.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "        img = plt.imshow(data[i].reshape(shape))\n",
    "        a.set_title('input')\n",
    "        \n",
    "        a=fig.add_subplot(1,2,2)\n",
    "        a.spines['top'].set_color('none')\n",
    "        a.spines['bottom'].set_color('none')\n",
    "        a.spines['left'].set_color('none')\n",
    "        a.spines['right'].set_color('none')\n",
    "        a.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "        img = plt.imshow(pred[i].reshape(shape))\n",
    "        a.set_title('decoded')\n",
    "        if(show_latent):\n",
    "            a.set_xlabel(vecs[i])\n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ImageSaver(Callback):\n",
    "    ''' Keras Callback to save demo images after each epoch'''\n",
    "    def __init__(self, image_path, images, shape, period=1, inp_path=None, out_path=None):\n",
    "        self.images = images\n",
    "        self.batch_size = images.shape[0]\n",
    "        self.image_path = image_path\n",
    "        self.shape = shape\n",
    "        self.period = period\n",
    "        self.inp_path = inp_path\n",
    "        self.out_path = out_path\n",
    "        \n",
    "        self.dpi = 128\n",
    "        self.fig_size = ((shape[0] * 4) // self.dpi, int(shape[1] * 1.5 * self.batch_size) // self.dpi)\n",
    "        \n",
    "        super(ImageSaver, self).__init__()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.period == 0:\n",
    "            vecs = self.model.layers[1].predict(self.images, batch_size=self.batch_size, verbose=0)\n",
    "            pred = self.model.layers[2].predict(vecs, batch_size=self.batch_size, verbose=0)\n",
    "        \n",
    "            if inp_path and out_path:\n",
    "                vecs.save\n",
    "        \n",
    "            fig = plt.figure(figsize=self.fig_size)\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                a = fig.add_subplot(self.batch_size, 2, i * 2 + 1)\n",
    "                a.spines['top'].set_color('none')\n",
    "                a.spines['bottom'].set_color('none')\n",
    "                a.spines['left'].set_color('none')\n",
    "                a.spines['right'].set_color('none')\n",
    "                a.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "                img = plt.imshow(self.images[i].reshape(shape))\n",
    "                a.set_title('input')\n",
    "                \n",
    "                a = fig.add_subplot(self.batch_size, 2, i * 2 + 2)\n",
    "                a.spines['top'].set_color('none')\n",
    "                a.spines['bottom'].set_color('none')\n",
    "                a.spines['left'].set_color('none')\n",
    "                a.spines['right'].set_color('none')\n",
    "                a.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "                img = plt.imshow(pred[i].reshape(shape))\n",
    "                a.set_title('decoded')\n",
    "            \n",
    "            fig.show()\n",
    "            fig.savefig(self.image_path.format(epoch=epoch), dpi=self.dpi)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using this on mnist data, just for a proof of concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28 ,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_generator(train_dir, batch_size):\n",
    "    files = os.listdir(train_dir)\n",
    "    \n",
    "    x_train = []\n",
    "    \n",
    "    while 1:\n",
    "        \n",
    "        for fname in os.listdir(train_dir):\n",
    "            x_train.append(imread(os.path.join(train_dir, fname)))\n",
    "            if len(x_train) >= batch_size:\n",
    "                print(x_train)\n",
    "                yield np.array(x_train), np.repeat(1, batch_size)\n",
    "                x_train = []\n",
    "            \n",
    "def valid_generator(valid_dir):\n",
    "    files = os.listdir(valid_dir)\n",
    "    \n",
    "    while 1:\n",
    "        for fname in files:\n",
    "            x_valid = imread(os.path.join(train_dir, fname))\n",
    "            yield x_valid, np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = train_generator('../scrape/flickr/abstract_art', 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hmm, I wasn't to happy with the mode collapse we were seeing from CVAEs, so let's try making a GAN now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_generator(output_shape, latent_dims, num_k=64, k_size=5, int_dim=256):\n",
    "    inp = Input(shape=(latent_dims,))\n",
    "    x = Dense(int_dim, activation='relu')(inp)\n",
    "    \n",
    "    v_dim = output_shape[0] // 4\n",
    "    h_dim = output_shape[1] // 4\n",
    "    v_rem = output_shape[0] - (v_dim * 4)\n",
    "    h_rem = output_shape[1] - (h_dim * 4)\n",
    "    \n",
    "    x = Dense(num_k // 2 * v_dim * h_dim, activation = 'relu')(x)\n",
    "    x = Reshape((v_dim, h_dim, num_k // 2))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    int_shape = (output_shape[0], output_shape[1], num_k)\n",
    "    params = {'activation' : 'relu', 'padding' : 'valid'}\n",
    "    p_params= {'pool_size' : (2,2), 'strides' : (2,2), 'padding' : 'same'}\n",
    "    \n",
    "    x = Conv2DTranspose(num_k, (k_size, k_size), strides=(1,1), activation = 'relu', padding='same')(x)\n",
    "\n",
    "    x = Conv2DTranspose(num_k*4, (k_size, k_size), strides=(2,2), padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    pad, v_rem, h_rem = build_padding(v_rem, h_rem, 8)\n",
    "    if pad:\n",
    "        x = pad(x)\n",
    "        \n",
    "    x = Conv2DTranspose(num_k*2, (k_size, k_size), strides=(2,2), padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    pad, v_rem, h_rem = build_padding(v_rem, h_rem, 4)\n",
    "    if pad:\n",
    "        x = pad(x)\n",
    "    \n",
    "    '''x = Conv2DTranspose(num_k, (k_size, k_size), strides=(2,2), padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    pad, v_rem, h_rem = build_padding(v_rem, h_rem, 2)\n",
    "    if pad:\n",
    "        x = pad(x)'''\n",
    "    \n",
    "    x = Conv2DTranspose(num_k, (k_size, k_size), strides=(2,2), padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = MaxPooling2D(**p_params)(x)\n",
    "    gen = Conv2D(output_shape[2], (4,4), padding = 'same', activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inp, gen)\n",
    "    \n",
    "    pad, v_rem, h_rem = build_padding(v_rem, h_rem, 4)\n",
    "    if pad:\n",
    "        x = pad(x)\n",
    "        \n",
    "    x = Conv2DTranspose(num_k*2, (k_size, k_size), strides=(2,2), activation = 'relu', padding='valid')(x)\n",
    "    pad, v_rem, h_rem = build_padding(v_rem, h_rem, 2)\n",
    "    if pad:\n",
    "        x = pad(x)\n",
    "        \n",
    "    x = Conv2DTranspose(num_k, (k_size, k_size), strides=(2,2), activation = 'relu', padding='valid')(x)\n",
    "    pad, v_rem, h_rem = build_padding(v_rem, h_rem, 1)\n",
    "    if pad:\n",
    "        x = pad(x)\n",
    "        \n",
    "    x = MaxPooling2D(**p_params)(x)\n",
    "    gen = Conv2D(output_shape[2], (4,4), padding = 'valid', activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inp, gen)\n",
    "\n",
    "\n",
    "def build_adversary(shape, num_k=64, k_size=4, int_dim=256):\n",
    "    c_params = {'padding' : 'same', 'activation' : LeakyReLU(alpha=0.2)}\n",
    "    p_params= {'pool_size' : (2,2), 'strides' : (2,2), 'padding' : 'same'}\n",
    "    \n",
    "    adv = Sequential()\n",
    "    adv.add(Conv2D(num_k, (k_size, k_size), input_shape=shape, **c_params))\n",
    "    adv.add(MaxPooling2D(**p_params))\n",
    "    adv.add(Dropout(0.4))\n",
    "    adv.add(Conv2D(num_k*2, (k_size, k_size), **c_params))\n",
    "    adv.add(MaxPooling2D(**p_params))\n",
    "    adv.add(Dropout(0.4))\n",
    "    adv.add(Conv2D(num_k*4, (k_size, k_size), **c_params))\n",
    "    adv.add(MaxPooling2D(**p_params))\n",
    "    adv.add(Dropout(0.4))\n",
    "    \n",
    "    adv.add(Flatten())\n",
    "    adv.add(Dense(int_dim, activation='relu'))\n",
    "    adv.add(Dense(2, activation='sigmoid'))\n",
    "    \n",
    "    return adv\n",
    "\n",
    "def build_GAN(shape, latent_dim, num_k=64, k_size=5, int_dim=256, g_opt='adamax', a_opt='adamax', gan_opt='adamax'):\n",
    "    generator = build_generator(shape, latent_dim, k_size=k_size, num_k=num_k, int_dim=int_dim)\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=g_opt)\n",
    "    \n",
    "    adversary = build_adversary(shape, num_k=num_k, k_size=k_size, int_dim=int_dim)\n",
    "    adversary.compile(loss='categorical_crossentropy', optimizer=a_opt)\n",
    "    \n",
    "    gan = Sequential()\n",
    "    gan.add(generator)\n",
    "    gan.add(adversary)\n",
    "    \n",
    "    gan.compile(loss='binary_crossentropy', optimizer=gan_opt)\n",
    "    \n",
    "    return generator, adversary, gan\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def demo_images(imgs, shape, filename=None):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    to_show = min(math.floor(math.sqrt(imgs.shape[0])), 4)\n",
    "    for i in range(to_show**2):\n",
    "        a = fig.add_subplot(to_show, to_show, i+1)\n",
    "        a.spines['top'].set_color('none')\n",
    "        a.spines['bottom'].set_color('none')\n",
    "        a.spines['left'].set_color('none')\n",
    "        a.spines['right'].set_color('none')\n",
    "        a.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "        \n",
    "        if len(shape) == 2:\n",
    "            img = plt.imshow(imgs[i].reshape(shape), cmap=plt.get_cmap('gray'))\n",
    "        else:\n",
    "            img = plt.imshow(imgs[i].reshape(shape))\n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        fig.savefig(filename)\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "def fit_gan(gen, adv, gan, data_stream, epochs, steps_per_epoch, latent_dims, shape):\n",
    "    # because we are doing our own training effectively\n",
    "    # we gotta keep track of losses independant of tensorflow\n",
    "    adv_loss = []\n",
    "    gan_loss = []\n",
    "    \n",
    "    if shape[2] == 1:\n",
    "        shape = (shape[0], shape[1])\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        adv_loss_ = []\n",
    "        gan_loss_ = []\n",
    "        for step in range(steps_per_epoch):\n",
    "            real_imgs = next(data_stream)\n",
    "            cur_batch_size = real_imgs.shape[0]\n",
    "            \n",
    "            # make batches\n",
    "            inp = np.random.uniform(-1.0, 1.0, size=(cur_batch_size, latent_dims)).astype('float32')\n",
    "            gen_imgs = gen.predict(inp)\n",
    "\n",
    "            # first let's train the adversary a bit\n",
    "            try:\n",
    "                X_batch = np.concatenate((real_imgs, gen_imgs))\n",
    "            except Exception as e:\n",
    "                print(real_imgs.shape)\n",
    "                print(gen_imgs.shape)\n",
    "                raise e\n",
    "            y_batch = np.zeros([2*cur_batch_size,2])\n",
    "            y_batch[cur_batch_size:,0] = 1\n",
    "            y_batch[:cur_batch_size,1] = 1\n",
    "\n",
    "            adv_loss_.append(adv.train_on_batch(X_batch, y_batch))\n",
    "\n",
    "            # now we can train the whole GAN\n",
    "            gaussian_noise = np.random.uniform(-1.0, 1.0, size=(cur_batch_size, latent_dims)).astype('float32')\n",
    "            y_g = np.zeros([cur_batch_size,2])\n",
    "            y_g[:,1] = 1\n",
    "            \n",
    "            gan_loss_.append(gan.train_on_batch(gaussian_noise, y_g))    \n",
    "        \n",
    "        adv_loss.append(sum(adv_loss_) / len(adv_loss_))\n",
    "        gan_loss.append(sum(gan_loss_) / len(gan_loss_))\n",
    "        \n",
    "        if i % 2 == 0:\n",
    "            demo_images(gen_imgs, shape, 'imgs{}.png'.format(i))\n",
    "            print(adv_loss)\n",
    "            print(gan_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = (28,28,1)\n",
    "latent_dim = 100\n",
    "batch_size = 128\n",
    "\n",
    "g_opt = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
    "a_opt = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
    "gan_opt = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
    "gen, adv, gan = build_GAN(shape, latent_dim, g_opt=g_opt, a_opt=a_opt, gan_opt=gan_opt)\n",
    "\n",
    "def mnist_data_gen(batch_size):\n",
    "    (x_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "    \n",
    "    x_len = len(x_train)\n",
    "\n",
    "    while 1:\n",
    "        for i in range(x_len // batch_size):\n",
    "            end_idx = min((i+1) * batch_size, x_len)\n",
    "            yield x_train[i * batch_size : end_idx, :, :, :]\n",
    "            \n",
    "            \n",
    "epochs = 100\n",
    "train_size = 8189\n",
    "steps_per_epoch = train_size // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit_gan(gen, adv, gan, mnist_data_gen(batch_size), epochs, steps_per_epoch, latent_dim, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = (64,64,1)\n",
    "latent_dim = 100\n",
    "batch_size = 32\n",
    "\n",
    "g_opt = keras.optimizers.RMSprop(lr=0.0002, clipvalue=1.0, decay=3e-8)\n",
    "a_opt = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=6e-8)\n",
    "gan_opt = keras.optimizers.RMSprop(lr=0.0002, clipvalue=1.0, decay=3e-8)\n",
    "\n",
    "#g_opt = keras.optimizers.Adamax(lr=0.001, clipvalue=1.0)\n",
    "#a_opt = keras.optimizers.Adamax(lr=0.002, clipvalue=1.0)\n",
    "#gan_opt = keras.optimizers.Adamax(lr=0.001, clipvalue=1.0)\n",
    "\n",
    "f_gen, f_adv, f_gan = build_GAN(shape, latent_dim, g_opt=g_opt, a_opt=a_opt, gan_opt=gan_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "train_size = 8189\n",
    "steps_per_epoch = train_size // batch_size\n",
    "train_data_dir = '../flowers/train'\n",
    "\n",
    "flower_train_generator = ImageDataGenerator(rescale=1/255).flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(shape[0], shape[1]),\n",
    "        color_mode='grayscale',\n",
    "        batch_size = batch_size,\n",
    "        class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit_gan(f_gen, f_adv, f_gan, flower_train_generator, epochs, steps_per_epoch, latent_dim, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = (128,128,3)\n",
    "latent_dims = 128\n",
    "batch_size = 16\n",
    "\n",
    "g_opt = keras.optimizers.RMSprop(lr=0.0008. decay=2e-8)\n",
    "a_opt = keras.optimizers.RMSprop(lr=0.0016, decay=4e-8)\n",
    "\n",
    "gen, adv, gan = build_GAN(shape, latent_dim, g_opt=g_opt, a_opt=a_opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GANs are a bit harder to train too, so we won't use built in fitting\n",
    "epochs = 50\n",
    "train_size = 100000\n",
    "\n",
    "steps_per_epoch = train_size // batch_size\n",
    "\n",
    "train_data_dir = '../faces/celebs/train'\n",
    "\n",
    "real_data_gen = ImageDataGenerator(rescale=1/255).flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(shape[0], shape[1]),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='none')\n",
    "\n",
    "fit_gan(adv, gan, real_data_gen, batch_size, epochs,\n",
    "        steps_per_epoch, latent_dims, shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepcv)",
   "language": "python",
   "name": "deepcv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
